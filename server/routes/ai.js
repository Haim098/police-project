const express = require('express')
const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require('@google/generative-ai')
const router = express.Router()
const config = require('../../config.js');
const geminiLiveService = require('../services/geminiLiveService');

// Initialize AI lazily to ensure environment variables are loaded
let genAI;
let model;

function getAiModel() {
  if (!model) {
    const geminiApiKey = config.gemini.apiKey;
    if (!geminiApiKey) {
      console.error("CRITICAL: GEMINI_API_KEY is not set in config.js. AI features will not work.");
      return null;
    }
    
    genAI = new GoogleGenerativeAI(geminiApiKey);
    model = genAI.getGenerativeModel({ 
  model: 'gemini-1.5-flash',
  generationConfig: {
    maxOutputTokens: 2048,
    temperature: 0.2,
  },
  // Disable safety settings for this specific use case
  safetySettings: [
    {
      category: HarmCategory.HARM_CATEGORY_HARASSMENT,
      threshold: HarmBlockThreshold.BLOCK_NONE,
    },
    {
      category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
      threshold: HarmBlockThreshold.BLOCK_NONE,
    },
    {
      category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
      threshold: HarmBlockThreshold.BLOCK_NONE,
    },
    {
      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
      threshold: HarmBlockThreshold.BLOCK_NONE,
    },
  ],
    });
  }
  return model;
}

// Emergency analysis prompt in Hebrew
const EMERGENCY_ANALYSIS_PROMPT = `
××ª×” ×ž×¢×¨×›×ª AI ×ž×ª×§×“×ž×ª ×œ×–×™×”×•×™ ×—×™×¨×•× ×¢×‘×•×¨ ×›×•×—×•×ª ×”×‘×™×˜×—×•×Ÿ ×‘×™×©×¨××œ. ××ª×” ×¨×•××” ×ª×ž×•× ×” ×©×¦×•×œ×ž×” ×ž×™×—×™×“×ª ×©×˜×—.

×—×©×•×‘ ×ž××•×“! ×”×©×ª×ž×© ×¨×§ ×‘×¡×•×’×™ ×”×–×™×”×•×™ ×”×‘××™× (×¨×©×™×ž×” ×ž×•×’×‘×œ×ª ×ž×‘×¡×™×¡ ×”× ×ª×•× ×™×):
- "fire" - ×œ×©×¨×™×¤×•×ª ×¤×¢×™×œ×•×ª, ×œ×”×‘×•×ª
- "smoke" - ×œ×¢×©×Ÿ ×ž×›×œ ×¡×•×’ (×©×—×•×¨, ×œ×‘×Ÿ, ×›×‘×“, ×§×œ)
- "person" - ×œ×× ×©×™× (×ž×‘×•×’×¨×™×, × ×¤×’×¢×™×, ×œ×›×•×“×™×)
- "child" - ×œ×™×œ×“×™× (×–×™×”×•×™ ×¡×¤×¦×™×¤×™ ×œ×§×˜×™× ×™×)
- "gas_tank" - ×œ×‘×œ×•× ×™ ×’×–, ×ž×™×›×œ×™ ×“×œ×§ ×ž×¡×•×›× ×™×
- "wire" - ×œ×—×•×˜×™× ×—×©×ž×œ×™×™× ×—×©×•×¤×™×, ×›×‘×œ×™× ×ž×¡×•×›× ×™×
- "structural_damage" - ×œ× ×–×§ ×ž×‘× ×™ (×›×•×œ×œ ×ž×‘× ×™× ×§×¨×•×¡×™×, ×¤×’×•×¢×™×, ×œ× ×™×¦×™×‘×™×, ×§×™×¨×•×ª ×©×‘×•×¨×™×)

××œ ×ª×©×ª×ž×© ×‘×¡×•×’×™× ××—×¨×™×! ×‘×ž×™×•×—×“ ××œ ×ª×©×ª×ž×© ×‘:
- electrical_hazard (×”×©×ª×ž×© ×‘-wire ×‘×ž×§×•×)
- explosion_risk (×”×©×ª×ž×© ×‘-gas_tank ×‘×ž×§×•×)
- vehicle (×œ× × ×ª×ž×š ×›×¨×’×¢)
- buildingCollapse ××• damagedBuilding (×”×©×ª×ž×© ×‘-structural_damage ×‘×ž×§×•×)

× ×ª×— ××ª ×”×ª×ž×•× ×” ×•×—×¤×©:
ðŸ”¥ ×©×¨×™×¤×•×ª, ×¢×©×Ÿ (×©×—×•×¨/×œ×‘×Ÿ), ×œ×”×‘×•×ª
ðŸ‘¥ ×× ×©×™× ×‘×¡×™×›×•×Ÿ, × ×¤×’×¢×™×, ×™×œ×“×™×, ×ž×‘×•×’×¨×™×
ðŸ  × ×–×§ ×ž×‘× ×™, ×§×™×¨×•×ª ×©×‘×•×¨×™×, ×ž×‘× ×™× ×¤×’×•×¢×™× ××• ×§×¨×•×¡×™×
âš¡ ×—×•×˜×™ ×—×©×ž×œ ×—×©×•×¤×™×, ×¡×›× ×•×ª ×—×©×ž×œ×™×•×ª  
ðŸ’¥ ×—×•×ž×¨×™× ×ž×¡×•×›× ×™×, ×‘×œ×•× ×™ ×’×–, ×¡×›× ×ª ×¤×™×¦×•×¥

×“×•×’×ž××•×ª ×œ×©×™×ž×•×© × ×›×•×Ÿ:
- ×ž×‘× ×” ×§×¨×•×¡/×¤×’×•×¢/×œ× ×™×¦×™×‘ â†’ "type": "structural_damage"
- ××“× ×ž×‘×•×’×¨/× ×¤×’×¢/×‘×¡×›× ×”/×œ×›×•×“ â†’ "type": "person"  
- ×™×œ×“/×§×˜×™×Ÿ/×™×œ×“×” â†’ "type": "child"
- ×‘×œ×•×Ÿ ×’×–/×ž×™×›×œ ×“×œ×§/×’×– â†’ "type": "gas_tank"
- ×—×•×˜ ×—×©×ž×œ ×—×©×•×£/×›×‘×œ ×¤×’×•×¢ â†’ "type": "wire"

×”×©×‘ ××š ×•×¨×§ ×‘×¤×•×¨×ž×˜ JSON ×”×‘×. ××œ ×ª×•×¡×™×£ ×©×•× ×˜×§×¡×˜ ××• ×”×¡×‘×¨ ×œ×¤× ×™ ××• ××—×¨×™ ×”-JSON.
{
  "urgent": true/false,
  "detections": [
    {
      "type": "fire/smoke/person/child/gas_tank/wire/structural_damage",
      "severity": "low/medium/high/critical/none", 
      "confidence": 0.0-1.0,
      "description": "×ª×™××•×¨ ×§×¦×¨ ×‘×¢×‘×¨×™×ª ×©×œ ×ž×” ×©×–×•×”×”. ×× ×œ× ×–×•×”×” ×›×œ×•×, ×›×ª×•×‘ '×œ×œ× ×–×™×”×•×™'.",
      "location": "×ž×™×§×•× ×›×œ×œ×™ ×©×œ ×”×–×™×”×•×™ ×‘×ª×ž×•× ×” (×œ×ž×©×œ, '×‘×ž×¨×›×– ×”×ª×ž×•× ×”', '×‘×¦×“ ×©×ž××œ ×œ×ž×¢×œ×”').",
      "action_required": "×¤×¢×•×œ×” × ×“×¨×©×ª ×ž×”×›×•×— ×‘×©×˜×—, ××• '××™×Ÿ ×¦×•×¨×š ×‘×¤×¢×•×œ×” ×ž×™×™×“×™×ª'.",
      "bounding_box": { "x": 0.0-1.0, "y": 0.0-1.0, "width": 0.0-1.0, "height": 0.0-1.0 }
    }
  ],
  "instructions": [
    "×”× ×—×™×” ××—×ª ×‘×¨×•×¨×” ×•×§×¦×¨×” ×œ×›×•×— ×‘×©×˜×—",
    "×”× ×—×™×” × ×•×¡×¤×ª ×× × ×“×¨×©"
  ],
  "priority": "low/medium/high/critical"
}

×× ×œ× ×–×™×”×™×ª ×©×•× ×“×‘×¨ ×ž×©×ž×¢×•×ª×™, ×”×©×‘ ×¢× "type": "none" ×•-"severity": "none".
`

// Live Analysis integration with existing Socket.IO
function setupLiveAnalysis(io) {
  console.log('ðŸŽ¥ Setting up Advanced Live Analysis with Socket.IO...')
  
  const activeSockets = new Set()

  io.on('connection', (socket) => {
    console.log('ðŸ”Œ AI route: Socket connected:', socket.id)

    // Handle live analysis session
    socket.on('start_live_analysis', async (data) => {
      try {
        console.log('ðŸŽ¥ Starting live analysis for unit:', data.unitId)
        
        const session = await geminiLiveService.createSession(socket.id, {
          unitId: data.unitId,
          features: data.features
        })

        socket.emit('live_analysis_ready', {
          sessionId: socket.id,
          message: 'Live analysis ready',
          features: {
            peopleDetection: true,
            fireAndSmokeAnalysis: true,
            structuralDamageAssessment: true,
            objectIdentification: true,
            sceneUnderstanding: true,
            riskAssessment: true,
            voiceAlerts: true,
            memoryRetention: true,
            electricalHazards: true,
            explosionDetection: true,
            chemicalHazards: true,
            timeBasedAnalysis: true
          }
        })
      } catch (error) {
        console.error('Error starting live analysis:', error)
        socket.emit('live_analysis_error', {
          message: 'Failed to start live analysis',
          error: error.message
        })
      }
    })

    // Handle frame analysis
    socket.on('analyze_frame', async (data) => {
      try {
        if (!data.frame) {
          throw new Error('No frame data provided')
        }

        // Analyze frame with Gemini
        const analysis = await geminiLiveService.analyzeFrame(socket.id, data.frame)
        
        // Send analysis result
        socket.emit('frame_analysis_result', analysis)

        // If urgent, broadcast to control centers
        if (analysis.currentFrame?.urgent) {
          // Find high severity detections
          const criticalDetections = analysis.currentFrame.detections.filter(d => 
            d.severity === 'critical' || d.severity === 'high'
          )

          if (criticalDetections.length > 0) {
            io.emit('live_detection_alert', {
              unitId: data.unitId,
              detections: criticalDetections,
              urgentMessage: analysis.currentFrame.urgentVoiceAlert,
              timestamp: new Date().toISOString()
            })
          }
        }

        // Send voice alert if needed
        if (analysis.currentFrame?.urgentVoiceAlert) {
          socket.emit('voice_alert', {
            message: analysis.currentFrame.urgentVoiceAlert,
            priority: 'urgent'
          })
        }

        // Check for explosion warnings
        const explosionDetection = analysis.currentFrame?.detections?.find(d => 
          d.type === 'gas_tank' || 
          (d.type === 'fire' && d.description?.includes('×¤×™×¦×•×¥'))
        )

        if (explosionDetection && explosionDetection.severity === 'critical') {
          socket.emit('emergency_explosion_warning', {
            message: '×–×”×™×¨×•×ª! ×¡×›× ×ª ×¤×™×¦×•×¥ ×ž×™×™×“×™×ª!',
            action: '×”×ª×¨×—×§ ×ž×”××–×•×¨ ×ž×™×“!',
            detection: explosionDetection
          })
        }

      } catch (error) {
        console.error('Error analyzing frame:', error)
        socket.emit('frame_analysis_error', {
          message: 'Failed to analyze frame',
          error: error.message
        })
      }
    })

    // Handle stop analysis
    socket.on('stop_live_analysis', async () => {
      try {
        await geminiLiveService.endSession(socket.id)
        socket.emit('live_analysis_stopped', {
          message: 'Live analysis stopped'
        })
      } catch (error) {
        console.error('Error stopping live analysis:', error)
      }
    })

    socket.on('disconnect', async () => {
      console.log('ðŸ”Œ AI route: Socket disconnected:', socket.id)
      // Clean up session
      try {
        await geminiLiveService.endSession(socket.id)
      } catch (error) {
        console.error('Error cleaning up session:', error)
      }
    })
  })
  
  console.log('âœ… Advanced Memory-Enhanced Live Analysis setup complete!')
}

// Mock live analysis for when Gemini is unavailable
function setupMockLiveAnalysis(socket, sessionId, unitId) {
  console.log(`ðŸŽ­ Setting up mock live analysis for unit ${unitId}`)
  
  socket.emit('live_analysis_ready', { 
    sessionId,
    message: 'Mock AI analysis activated (Gemini unavailable)',
    isMock: true
  })
  
  // Mock analysis every 5 seconds
  const mockInterval = setInterval(() => {
    if (Math.random() > 0.7) { // 30% chance of detection
      const mockDetections = [
        {
          type: 'fire',
          severity: 'critical',
          confidence: 0.85,
          description: '×–×•×”×ª×” ×©×¨×™×¤×” ×¤×¢×™×œ×”',
          location: '×—×œ×§ ×ž×¨×›×–×™ ×©×œ ×”×©×˜×—',
          action_required: '×¤× ×” ×ž×”××–×•×¨ ×ž×™×™×“×™×ª'
        },
        {
          type: 'smoke',
          severity: 'high',
          confidence: 0.78,
          description: '×–×•×”×” ×¢×©×Ÿ ×›×‘×“',
          location: '×‘×—×œ×§ ×”×¦×¤×•× ×™',
          action_required: '×”×™×ž× ×¢ ×ž×©××™×¤×”'
        },
        {
          type: 'person',
          severity: 'medium',
          confidence: 0.92,
          description: '×–×•×”×• ×× ×©×™× ×‘××–×•×¨',
          location: '×œ×™×“ ×”×›× ×™×¡×”',
          action_required: '×‘×“×•×§ ×ž×¦×‘ ×”× ×¤×’×¢×™×'
        }
      ]
      
      const detection = mockDetections[Math.floor(Math.random() * mockDetections.length)]
      
      socket.emit('live_analysis_result', {
        sessionId,
        analysis: {
          urgent: detection.severity === 'critical',
          detections: [detection],
          instructions: [
            '×“×•×•×— ×œ×ž×¨×›×– ×”×©×œ×™×˜×”',
            detection.action_required,
            '×”×ž×ª×Ÿ ×œ×”×•×¨××•×ª × ×•×¡×¤×•×ª'
          ],
          priority: detection.severity,
          timestamp: new Date().toISOString(),
          session_id: sessionId,
          isMock: true
        }
      })
    }
  }, 5000)
  
  socket.on('disconnect', () => {
    clearInterval(mockInterval)
  })
}

// Legacy analyze-frame endpoint (still available for manual analysis)
router.post('/analyze-frame', async (req, res) => {
  try {
    const { unitId, frame } = req.body

    if (!unitId) {
      return res.status(400).json({
        error: 'Unit ID is required'
      })
    }

    console.log(`ðŸ“¸ Manual frame analysis for unit ${unitId}`)

    // Check if we have real frame data
    if (frame && frame !== 'mock_frame_data' && frame.startsWith('data:image')) {
      const aiModel = getAiModel();
      if (!aiModel) {
        console.warn('âš ï¸ Gemini API key not found in config.js, using mock analysis')
        return performMockAnalysis(unitId, res)
      }

      try {
        const frameImage = processFrameData(frame)
        if (!frameImage) {
          throw new Error('Invalid frame data format')
        }

        const result = await aiModel.generateContent([
          EMERGENCY_ANALYSIS_PROMPT,
          frameImage
        ])
        
        const response = await result.response
        const analysisText = response.text()
        
        // Try to parse JSON response
        let analysis
        try {
          const jsonMatch = analysisText.match(/\{[\s\S]*\}/)
          if (jsonMatch) {
            analysis = JSON.parse(jsonMatch[0])
          } else {
            throw new Error('No JSON found in response')
          }
        } catch (parseError) {
          console.warn('âš ï¸ Failed to parse AI response from manual analysis')
          return res.status(500).json({
            success: false,
            error: 'AI_RESPONSE_PARSE_ERROR',
            message: 'The AI returned a response that could not be understood.'
          })
        }

        return res.json({
          success: true,
          unitId,
          analysis: {
            ...analysis,
            timestamp: new Date().toISOString(),
            processing_time: '2.1s',
            ai_model: 'gemini-1.5-flash'
          }
        })

      } catch (aiError) {
        console.error('ðŸš¨ Gemini AI failed:', aiError.message)
        return res.status(500).json({ 
          success: false, 
          error: 'AI_ANALYSIS_FAILED', 
          message: aiError.message 
        })
      }
    } else {
      return performMockAnalysis(unitId, res)
    }

  } catch (error) {
    console.error('AI Analysis error:', error)
    res.status(500).json({
      error: 'AI analysis failed',
      message: error.message
    })
  }
})

// Helper function to process base64 frame data
function processFrameData(frameData) {
  if (!frameData || typeof frameData !== 'string') {
    return null
  }
  
  const base64Data = frameData.includes(',') ? frameData.split(',')[1] : frameData
  
  return {
    inlineData: {
      data: base64Data,
      mimeType: 'image/jpeg'
    }
  }
}

// Mock analysis helper (unchanged)
function performMockAnalysis(unitId, res) {
  setTimeout(() => {
    const scenarios = [
      {
        type: 'fire',
        confidence: 0.85,
        severity: 'critical',
        description: '×–×•×”×ª×” ×©×¨×™×¤×” ×¤×¢×™×œ×” ×‘××–×•×¨',
        location: '×—×œ×§ ×ž×¨×›×–×™',
        action_required: '×¤× ×” ×ž×”××–×•×¨ ×ž×™×™×“×™×ª'
      },
      {
        type: 'smoke',
        confidence: 0.78,
        severity: 'high', 
        description: '×–×•×”×” ×¢×©×Ÿ ×›×‘×“',
        location: '×—×œ×§ ×¦×¤×•× ×™',
        action_required: '×”×™×ž× ×¢ ×ž×©××™×¤×”'
      },
      {
        type: 'person',
        confidence: 0.92,
        severity: 'medium',
        description: '×–×•×”×• ×× ×©×™× ×‘××–×•×¨',
        location: '×œ×™×“ ×”×›× ×™×¡×”',
        action_required: '×‘×“×•×§ ×ž×¦×‘ ×”× ×¤×’×¢×™×'
      }
    ]

    const shouldDetect = Math.random() > 0.6
    const selectedScenario = scenarios[Math.floor(Math.random() * scenarios.length)]

    const analysis = {
      urgent: shouldDetect && selectedScenario.severity === 'critical',
      detections: shouldDetect ? [selectedScenario] : [],
      instructions: shouldDetect ? [
        '×“×•×•×— ×œ×ž×¨×›×– ×”×©×œ×™×˜×”',
        selectedScenario.action_required,
        '×”×ž×ª×Ÿ ×œ×”×•×¨××•×ª × ×•×¡×¤×•×ª'
      ] : ['×”×ž×©×š ×‘×¡×™×•×¨ ×¨×’×™×œ'],
      priority: shouldDetect ? selectedScenario.severity : 'low',
      timestamp: new Date().toISOString(),
      processing_time: '1.2s',
      ai_model: 'mock_system'
    }

    res.json({
      success: true,
      unitId,
      analysis
    })
  }, 1000)
}

// Gemini TTS endpoint - Using Gemini 2.5 Flash for natural Hebrew speech
router.post('/tts', async (req, res) => {
  // ===== Gemini Native TTS Implementation =====
  // This endpoint now generates real audio (Base64) using Gemini 2.5 native TTS
  // and returns it to the client with a format field so that the front-end can
  // play it without falling back to the Web Speech API.

  try {
    const { text, priority = 'normal', emotion = 'neutral', rate = 'normal' } = req.body

    if (!text) {
      return res.status(400).json({
        error: 'Text is required',
        message: 'Please provide text to synthesize'
      })
    }

    // Ensure Gemini API key configured
    if (!genAI) {
      return res.status(503).json({
        error: 'AI service unavailable',
        message: 'Gemini AI is not configured. Please check API key in config.js'
      })
    }

    // Select voice according to priority / emotion (simple mapping for now)
    const voiceMap = {
      critical: 'Kore',
      high: 'Fenrir',
      medium: 'Enceladus',
      low: 'Umbriel'
    }
    const selectedVoice = voiceMap[priority] || 'Kore'

    // Generate AUDIO response
    const ttsResponse = await genAI.generateContent({
      model: 'gemini-2.5-flash-preview-tts',
      contents: [{ parts: [{ text }] }],
      generationConfig: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: {
              voiceName: selectedVoice
            }
          }
        }
      }
    })

    const audioPart = ttsResponse.response.candidates?.[0]?.content?.parts?.[0]

    if (!audioPart || !audioPart.inlineData || !audioPart.inlineData.data) {
      throw new Error('Gemini TTS returned no audio')
    }

    const base64Audio = audioPart.inlineData.data // PCM base64
    const mimeType = audioPart.inlineData.mimeType || 'audio/wav'

    return res.json({
      success: true,
      audio: base64Audio,
      format: mimeType
    })
  } catch (error) {
    console.error('TTS generation error:', error)
    res.status(500).json({
      error: 'TTS generation failed',
      message: error.message,
      fallback_available: true
    })
  }
})

module.exports = {
  router,
  setupLiveAnalysis
} 